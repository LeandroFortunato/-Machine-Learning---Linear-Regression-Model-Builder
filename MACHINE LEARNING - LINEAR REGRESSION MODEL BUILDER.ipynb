{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[36m \n",
      " MACHINE LEARNING - LINEAR REGRESSION MODEL BUILDER \n",
      "\n",
      "\u001b[1m \u001b[31m \n",
      "Informe path/name of CSV file:  (<ENTER> to abort)\n",
      "C:/Users/p_com/Downloads/auto_prices.csv\n",
      "\n",
      "Opening file ...\n",
      "Done !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaba7b0bfdc64eb69636e0d3bb5c0643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='target', options=('Unnamed: 0', 'Unnamed: 0.1', 'bore', 'city-L/10â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def choose_target_features(target,feature,confirm):\n",
    "   \n",
    "    global df\n",
    "    \n",
    "\n",
    "    if  target == feature:\n",
    "        \n",
    "        print(c_bold,c_red,\"\\nTarget and feature can't be the same ! \\n\")\n",
    "        ws.Beep(1000,1000)\n",
    "        \n",
    "    elif confirm == 'Yes': \n",
    "    \n",
    "        build_model(df,target,feature)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('')\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "def next_color(p_par): \n",
    "    \n",
    "    global x_color\n",
    "    \n",
    "    if  p_par == 1:\n",
    "  \n",
    "        if  x_color == 36:\n",
    "            x_color = 30\n",
    "\n",
    "        x_color += 1       \n",
    "        \n",
    "    else:    \n",
    "\n",
    "        x_color = 31 # Return to first color\n",
    "       \n",
    "                \n",
    "    return('\\033[1m \\033[%im' % (x_color))\n",
    "\n",
    "\n",
    "    \n",
    "def build_model(df,target,feature):   \n",
    "   \n",
    "    \n",
    "    global x_test,y_test\n",
    "    \n",
    "   \n",
    "    if feature == '- All features -': \n",
    "\n",
    "        df_feature_corr_level = df.corr()[target][df.corr()[target] >= 0.7].sort_values()\n",
    "        df_feature_corr_level.drop(labels = target, inplace = True)\n",
    "        \n",
    "        print(next_color(1),\n",
    "              '\\n Features identified on file that present a linear tendency with the target',\n",
    "               next_color(1),\n",
    "               target.upper(),\n",
    "               next_color(0),\n",
    "               '(correlation coeficient >= 0.7):') # goes back to first color\n",
    "\n",
    "        print(next_color(1))\n",
    "\n",
    "        for index,value in enumerate(df_feature_corr_level):\n",
    "            print('  -  ' + df_feature_corr_level.index[index],' (%f' % (value)+')')      \n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "        combinations = list(itertools.chain(*[itertools.combinations(df_feature_corr_level.index, i+1) for i in range(len(df_feature_corr_level.index))]))\n",
    "        \n",
    "        \n",
    "    else:    \n",
    "        \n",
    "        if  df.corr()[target][feature] < 0.7:\n",
    "            comparison_to_07 = '(< 0.7)'\n",
    "        else:    \n",
    "            comparison_to_07 = '(>= 0.7)'\n",
    "\n",
    "\n",
    "        print(c_bold+c_red\n",
    "              +'\\n Correlation coeficient between target',\n",
    "              c_bold,c_blue,\n",
    "              target.upper(),\n",
    "              c_bold,c_red,\n",
    "              'and feature',\n",
    "              c_bold,c_blue,\n",
    "              feature.upper(),\n",
    "              c_bold,c_red,\n",
    "              '=====> '\n",
    "              +c_bold+c_yellow,\n",
    "              df.corr()[target][feature],\n",
    "              c_bold+c_red,\n",
    "              comparison_to_07)\n",
    "\n",
    "        combinations = [(feature,)]\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    best_combination = \"\"\n",
    "    best_number_of_parts = 0\n",
    "\n",
    "\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    sd = StandardScaler()\n",
    "\n",
    "    data_out = 0  # to be removed later (processing just 75% of data)\n",
    "\n",
    "    \n",
    "    \n",
    "    if  data_out != 0:  # in case of precision test\n",
    "  \n",
    "        df,x_test,df[target],y_test = train_test_split(df.drop(target,axis=1),df[target],test_size=(data_out/100),random_state=0)\n",
    "    \n",
    "    \n",
    "    print(next_color(1),'\\n Using %i'  % (100-data_out),'%','percentage of data to build up model')\n",
    "    #print(next_color(1),'\\n Building up model...')\n",
    "\n",
    "    for order in range(1,6,1):\n",
    "\n",
    "        pf = PolynomialFeatures(degree=order,include_bias = None)    \n",
    "\n",
    "        if len(combinations) > 1:\n",
    "            print(next_color(1),'\\n\\n ------- Checking relevant features for an order-%i model...\\n ' % (order))\n",
    "        else:\n",
    "            print(next_color(1),'\\n\\n ------- Checking scores for an order-%i model...\\n ' % (order))\n",
    "            \n",
    "\n",
    "        for n_parts in range(2,6,1):\n",
    "\n",
    "            if len(combinations) > 1:\n",
    "                print('Grid-Searching them with %i fold(s) ...' % (n_parts))\n",
    "            else:\n",
    "                print('Grid-Searching it with %i fold(s) ...' % (n_parts))\n",
    "\n",
    "                \n",
    "            for features in combinations:\n",
    "\n",
    "                gs = GridSearchCV(lr,{},cv=n_parts)\n",
    "\n",
    "                poly_boxes = pf.fit_transform(df[list(features)])\n",
    "\n",
    "                features_score = gs.fit(poly_boxes,df[target]).best_score_\n",
    "\n",
    "\n",
    "                if  features_score >  best_score: \n",
    "                    best_score =  features_score\n",
    "                    best_order = order\n",
    "                    best_combination = list(features)\n",
    "                    best_number_of_parts =  n_parts\n",
    "\n",
    " \n",
    "        if  len(combinations) > 1:\n",
    "            print('\\n ----- Results ------> Most relevant futures sor far: ',best_combination)   \n",
    " \n",
    "        if best_score > 0:\n",
    "            print('\\n                       Best order so far............: ',best_order)        \n",
    "            print('\\n                       Best cross-validation........: ',best_number_of_parts,' fold(s)')  \n",
    "            print('\\n                       Score for above..............: ',best_score)\n",
    "\n",
    "\n",
    "    ##################### Evaluates any improvement of model above with Ridge Regression ##################        \n",
    "\n",
    "    \n",
    "    \n",
    "    print(next_color(1),'\\n\\n Using Ridge Regression to improve model with the paramaters above ...')\n",
    "\n",
    "\n",
    "    pf = PolynomialFeatures(degree=best_order,include_bias=False)\n",
    "\n",
    "    poly_boxes = pf.fit_transform(sd.fit_transform(df[best_combination]))\n",
    "\n",
    "    rr = Ridge()\n",
    "\n",
    "    standard_amount = 10**-6\n",
    "\n",
    "    alpha_max = 0\n",
    "\n",
    "    increment = 0   \n",
    "\n",
    "\n",
    "    while increment != standard_amount:\n",
    "\n",
    "        increment = standard_amount\n",
    "\n",
    "        print('\\n Grid-Searching with alpha: ',alpha_max + increment)\n",
    "\n",
    "\n",
    "        while True:\n",
    "\n",
    "            gs = GridSearchCV(rr,{'alpha':[alpha_max + increment]},cv=best_number_of_parts)\n",
    "            score_1 = gs.fit(poly_boxes,df[target]).best_score_\n",
    "\n",
    "            gs = GridSearchCV(rr,{'alpha':[alpha_max + increment+standard_amount]},cv=best_number_of_parts)\n",
    "            score_2 = gs.fit(poly_boxes,df[target]).best_score_\n",
    "\n",
    "\n",
    "            if  score_1 <= score_2:\n",
    "                increment *= 2  \n",
    "            else:\n",
    "                if  increment != standard_amount: # processed above at least once \n",
    "                    alpha_max += increment/2 # equal last increment \n",
    "                break\n",
    "\n",
    "\n",
    "    best_alpha = alpha_max\n",
    "\n",
    "    gs = GridSearchCV(rr,{'alpha':[alpha_max]},cv=best_number_of_parts)\n",
    "\n",
    "    print('\\n New score obtained: %f (%.2f' \n",
    "                           %\n",
    "                           (gs.fit(poly_boxes,df[target]).best_score_, \n",
    "                           ((gs.fit(poly_boxes,df[target]).best_score_/best_score)-1)*100),\n",
    "                           '% improvement) \\n')   \n",
    "\n",
    "    \n",
    "    \n",
    "    ########################## Model constituted by (1-1/cv) [Training Data] #################################\n",
    "    ################## This part will show performance of model over unseen (1/cv) [Testing Data]  \n",
    "\n",
    "\n",
    "\n",
    "    pf = PolynomialFeatures(degree=best_order,include_bias=False)\n",
    "\n",
    "    poly_boxes = pf.fit_transform(sd.fit_transform(df[best_combination]))\n",
    "\n",
    "    lr = Ridge(best_alpha)\n",
    "\n",
    "    y_predict = cross_val_predict(lr,poly_boxes,df[target],cv=best_number_of_parts)\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    plt.title('Population Distribution on '+ target)\n",
    "    plt.ylabel('Population')\n",
    "\n",
    "    sns.distplot(df[target], hist=False, color='r', label='Actual '+ target)\n",
    "    sns.distplot(y_predict,   hist=False, color='b', label='Predicted '+ target)\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    training_percentage = (1-(1/best_number_of_parts))*100\n",
    "\n",
    "    print(next_color(1))\n",
    "\n",
    "    print('\\n********* FINAL RESULTS ***********\\n')\n",
    "\n",
    "    print('Polynomial order................:  %i' % (best_order))\n",
    "\n",
    "    print('Bias included (alpha)...........:  %f' % (best_alpha))\n",
    "\n",
    "    print('Predicted Price.................:  Model constituted on ' \n",
    "                         +'%.2f' % (training_percentage),\n",
    "                          '%',\n",
    "                          'of Training Data (Cross Validation with %i parts' % (best_number_of_parts)\n",
    "                         +')')\n",
    "\n",
    "    print('R2 on Testing Data %.2f' % (100-training_percentage),\n",
    "                          '%','.....: ',r2_score(df[target],y_predict),\n",
    "                          '(Cross Validation with %i parts' % (best_number_of_parts)+')')\n",
    "\n",
    "\n",
    "    ################### This part will show model constituted by 100% Data ########                \n",
    "\n",
    "    pf = PolynomialFeatures(degree=best_order,include_bias=False)\n",
    "\n",
    "    poly_boxes = pf.fit_transform(df[best_combination])\n",
    "\n",
    "    all_terms = pf.get_feature_names()\n",
    "\n",
    "    for term_position,term in enumerate(all_terms):\n",
    "\n",
    "        for feature_position,feature in enumerate(best_combination):\n",
    "            all_terms[term_position]= all_terms[term_position].replace('x'+str(feature_position),\"(\"+feature+\")\") \n",
    "\n",
    "\n",
    "    lr.fit(poly_boxes,df[target])\n",
    "    \n",
    "    \n",
    "    if  len(best_combination) == 1:  #just 1 dimension\n",
    "        \n",
    "        plt.figure(figsize=(16,6))\n",
    "        \n",
    "        plt.title(best_combination[0] + ' X ' +  target)\n",
    "        plt.xlabel(best_combination[0])\n",
    "        plt.ylabel(target)\n",
    "        \n",
    "        plt.plot(df[best_combination],df[target],'ro',label='Data')\n",
    "        \n",
    "        poly_boxes_sorted = pf.fit_transform(pd.DataFrame(np.sort(df[best_combination[0]])))\n",
    "       \n",
    "        plt.plot(np.sort(df[best_combination[0]]), lr.predict(poly_boxes_sorted),'b',linewidth = \"3.0\",label='Model')\n",
    "        \n",
    "        plt.legend(loc='best')\n",
    "\n",
    "\n",
    "    print(next_color(1))\n",
    "\n",
    "    print('R2 on Training Data 100',   '%','......: ',lr.score(poly_boxes,df[target]))\n",
    "    print('Model on Training Data 100','%','...:  yhat = %+f' % (lr.intercept_))\n",
    "    for parameter in range(0,len(lr.coef_),1):\n",
    "        print(' '*42+\" %+f\" % (lr.coef_[parameter]) + \"*(\"+ all_terms[parameter] + \")\")    \n",
    "\n",
    "    print(color_off)\n",
    "\n",
    "\n",
    "\"\"\"  ##############################################################################\n",
    "    if  data_out != 0:  # in case of precision test\n",
    "    \n",
    "        poly_boxes = pf.fit_transform(x_test[best_combination])\n",
    "\n",
    "        print(lr.score(poly_boxes,y_test))\n",
    "        \n",
    "\n",
    "        print(r2_score(y_test,lr.predict(poly_boxes)))\n",
    "############################################################################## \"\"\"     \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "############################# Cross Validation with Ridge Regression Refinement\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from ipywidgets import interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import winsound as ws\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "x_color = 35\n",
    "\n",
    "c_bold = '\\033[1m' \n",
    "c_red = \"\\033[31m\" \n",
    "c_blue = '\\033[34m' \n",
    "c_yellow = '\\033[33m'\n",
    "color_off = '\\033[0m'\n",
    "\n",
    "\n",
    "print(next_color(1),'\\n','Machine Learning - Linear Regression Model builder'.upper(),'\\n')\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    print(next_color(1),'\\nInforme path/name of CSV file:  (<ENTER> to abort)')\n",
    "    file_name = input()\n",
    "        \n",
    "    if  file_name == '':\n",
    "\n",
    "        print('Program aborted !')\n",
    "        print('---------------\\n')\n",
    "        ws.Beep(500,1000)\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "            \n",
    "        print('\\nOpening file ...')\n",
    "        df = pd.read_csv((file_name.strip()))\n",
    "        print('Done !')\n",
    "\n",
    "        #'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/module_5_auto.csv'\n",
    "\n",
    "        df=df._get_numeric_data()\n",
    "\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "\n",
    "        options   = df.columns.sort_values()\n",
    "\n",
    "        break\n",
    "\n",
    "    except: \n",
    " \n",
    "        if  IOError:\n",
    "            print('File not found !\\n')\n",
    "        else:\n",
    "            print('Unidentified error !\\n')\n",
    "   \n",
    "        ws.Beep(1000,1000)\n",
    "\n",
    "if  file_name != '':\n",
    "\n",
    "    interact(choose_target_features, target = options, feature=options.insert(0,'- All features -'), confirm=['No','Yes'])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
